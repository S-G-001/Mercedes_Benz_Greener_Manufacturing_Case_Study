{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import pylab as py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from tqdm import tqdm \n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Load & Prepare The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test data\n",
    "\n",
    "train_raw = pd.read_csv('Data/train_data/train.csv')\n",
    "test_raw = pd.read_csv('Data/test_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating target variable from the rest of the features\n",
    "\n",
    "y_raw = train_raw['y']\n",
    "x_raw = train_raw.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing categorical features in a seperate variable\n",
    "\n",
    "categorical_features = ['X0','X1','X2','X3','X4','X5','X6','X8']\n",
    "train_categorical = train_raw[categorical_features]\n",
    "test_categorical = test_raw[categorical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one hot encoding for categorical variables\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder = encoder.fit(train_categorical)\n",
    "train_categorical_ohe = encoder.transform(train_categorical)\n",
    "test_categorical_ohe = encoder.transform(test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape (4209, 195)\n",
      "Train data shape (4209, 195)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the one hot encoded categorical feature datframe\n",
    "\n",
    "print('Train data shape',train_categorical_ohe.toarray().shape)\n",
    "print('Train data shape',test_categorical_ohe.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the binary features in a new variable\n",
    "\n",
    "train_binary_features = train_raw.iloc[:,10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Feature Set 1 : Original Features With Zero Tempering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Concatanate All the Features -  Binary, Categorical and ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the training data for Feature set 1:  (4209, 564)\n"
     ]
    }
   ],
   "source": [
    "# Concatanate all the features\n",
    "\n",
    "train_data_1 = np.hstack((np.array(train_raw.ID).reshape(-1,1),train_categorical_ohe.toarray(),train_binary_features))\n",
    "print('shape of the training data for Feature set 1: ',train_data_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) RF Model Using Feature Set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1) Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=3, n_estimators=20, random_state=3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a Randomforestregressor on Feature set 1\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=20, max_depth=3, random_state=3)\n",
    "rf.fit(train_data_1,y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2) Get R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for training data set 1:  0.576\n",
      "Adjusted R2 for training data set 1:  0.544\n"
     ]
    }
   ],
   "source": [
    "# Get R2 score and adjusted R2 score for training\n",
    "\n",
    "r2_training1 =  round(r2_score(y_raw,rf.predict(train_data_1)),3)\n",
    "adjusted_r2_training1 = round(1 - (((1 - r2_training)*(len(y_raw)-1))/(len(y_raw) - train_data_1.shape[1] -1)),3)\n",
    "\n",
    "\n",
    "print('R2 for training data set 1: ', r2_training1)\n",
    "print('Adjusted R2 for training data set 1: ', adjusted_r2_training1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3) Get Cross_val R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared cross validation:  0.512\n",
      "Adjusted R-squared cross validation:  0.46\n"
     ]
    }
   ],
   "source": [
    "# Get Cross_val R2 score and adjusted R2 score\n",
    "\n",
    "r2_cv1 = round(np.mean(cross_val_score(rf,train_data_1,y_raw,cv=4, scoring='r2')),3)\n",
    "adjusted_r2_cv1 =  round(1 - (1 - r2_cv)*(len(y_raw)-1)/(len(y_raw) - train_data_1.shape[1] -1),3)\n",
    "\n",
    "print('R-squared cross validation: ', r2_cv1)\n",
    "print('Adjusted R-squared cross validation: ', adjusted_r2_cv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Feature Set 2 : Remove Features With Very Small Individual R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Discover the Least Scoring features individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1)  Use RF to get R2 scores for individual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score when we use all the binary features:  0.5745\n"
     ]
    }
   ],
   "source": [
    "# find the R2 score when using only all the binary features.\n",
    "# find the individual R2 score for each binary feature.\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=20, max_depth=3, random_state=3) \n",
    "rf.fit(train_binary_features,y_raw)\n",
    "y_pred_train = rf.predict(train_binary_features)\n",
    "train_score = r2_score(y_raw,y_pred_train)\n",
    "print('R2 score when we use all the binary features: ',round(train_score,4))\n",
    "\n",
    "R2_binary_fea = {} # store the individual R2 scores of binary features in R2_binary_fea\n",
    "for i in train_binary_features.columns:\n",
    "    tr_data = np.array(train_binary_features[i]).reshape(-1,1)\n",
    "    rf = RandomForestRegressor(n_estimators=20, max_depth=3, random_state=3)\n",
    "    rf.fit(tr_data,y_raw)\n",
    "    y_pred_train = rf.predict(tr_data)\n",
    "    train_score = r2_score(y_raw,y_pred_train)\n",
    "    R2_binary_fea[i] = train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2) Collect the least scoring features names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get binary features with a negative or very small R-squared score\n",
    "binary_features_small_r2 = []\n",
    "for i in (sorted(R2_binary_fea.items(), key = lambda item:item[1])):\n",
    "  if i[1] < 0.0005:                 # this threshold was chosen intuitively with some trial and error \n",
    "        binary_features_small_r2.append(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Prepare data for Feature Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the set 2 train data:  (4209, 460)\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset for set 2\n",
    "# Remove 'X4' because it has very small variance as seen during EDA.\n",
    "\n",
    "categorical_features_set_2 = ['X0','X1','X2','X3','X5','X6','X8']   # 'X4' not included\n",
    "train_categorical_set_2 = train_raw[categorical_features_set_2]\n",
    "\n",
    "# perform one hot encoding for remaining categorical features.\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder = encoder.fit(train_categorical_set_2)\n",
    "train_categorical_ohe_set_2 = encoder.transform(train_categorical_set_2)\n",
    "\n",
    "# Drop the binary features having a very small individual R2.\n",
    "train_binary_features_set_2 = train_binary_features.drop(binary_features_small_r2, axis=1)\n",
    "\n",
    "#concatanate ID, Categorical Features, Binary Features\n",
    "train_data_2 = np.hstack((np.array(train_raw.ID).reshape(-1,1),train_categorical_ohe_set_2.toarray(),train_binary_features_set_2))\n",
    "print('shape of the set 2 train data: ',train_data_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) RF Model Using Feature Set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1) Fit the RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=3, n_estimators=20, random_state=3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a RF regressor on Feature Set 2\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=20, max_depth=3, random_state=3)\n",
    "rf.fit(train_data_2,y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2) Get R2 score for Feature set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for training data set 2:  0.576\n",
      "Adjusted R-squared for training data set 2:  0.557\n"
     ]
    }
   ],
   "source": [
    "# R2 score for training data set 2\n",
    "\n",
    "r2_training2 =  round(r2_score(y_raw,rf.predict(train_data_2)),3)\n",
    "adjusted_r2_training2 = round(1 - (((1 - r2_training)*(len(y_raw)-1))/(len(y_raw) - train_data_2.shape[1] -1)),3)\n",
    "\n",
    "print('R-squared for training data set 2: ', r2_training2)\n",
    "print('Adjusted R-squared for training data set 2: ', adjusted_r2_training2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3) Get Cross_val R2 score for set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation R-squared  for set 2:  0.511\n",
      "cross validation Adjusted R-squared  for set 2:  0.475\n"
     ]
    }
   ],
   "source": [
    "# corss_val R2 score for set 2\n",
    "\n",
    "r2_cv2 = round(np.mean(cross_val_score(rf,train_data_2,y_raw,cv=4, scoring='r2')),3)\n",
    "adjusted_r2_cv2 =  round(1 - (((1 - r2_cv)*(len(y_raw)-1))/(len(y_raw) - train_data_2.shape[1] -1)),3)\n",
    "\n",
    "print('cross validation R-squared  for set 2: ', r2_cv2)\n",
    "print('cross validation Adjusted R-squared  for set 2: ',adjusted_r2_cv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.) Feature Set 3 : Remove the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1) Prepare the data for Model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1) Remove the Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the extreme outlier.\n",
    "\n",
    "train_categorical_ohe_set_3 = np.delete(train_categorical_ohe_set_2.toarray(),883,0)\n",
    "train_binary_features_set_3 = train_binary_features_set_2.drop(labels=883, axis=0)\n",
    "ID_set_3 = np.array(train_raw.ID.drop(labels=883, axis=0)).reshape(-1,1)\n",
    "y_set_3 = train_raw['y'].drop(labels=883, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2) Concatanate all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the Set 3 train data:  (4208, 460)\n"
     ]
    }
   ],
   "source": [
    "# Concatanate all categorical,ID, Binary features after removing the outlier\n",
    "\n",
    "train_data_3 = np.hstack((ID_set_3,train_categorical_ohe_set_3,train_binary_features_set_3))\n",
    "print('shape of the Set 3 train data: ',train_data_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) RF Regression Using Set 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1) Build the RF Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=3, n_estimators=20, random_state=3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a RF regressor on Feature Set 3 \n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=20, max_depth=3, random_state=3)\n",
    "rf.fit(train_data_3,y_set_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2) Get R2 score for Feature Set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for training data set 3:  0.603\n",
      "Adjusted R-squared for training data set 3:  0.557\n"
     ]
    }
   ],
   "source": [
    "# R2 score for training Feature set 3\n",
    "\n",
    "r2_training3 =  round(r2_score(y_set_3,rf.predict(train_data_3)),3)\n",
    "adjusted_r2_training3 = round(1 - (((1 - r2_training)*(len(y_set_3)-1))/(len(y_set_3) - train_data_3.shape[1] -1)),3)\n",
    "\n",
    "print('R-squared for training data set 3: ', r2_training3)\n",
    "print('Adjusted R-squared for training data set 3: ', adjusted_r2_training3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3) Get Cross_val R2 Score for Set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared cross validation  for data set 3:  0.523\n",
      "Adjusted R-squared cross validation  for data set 3:  0.475\n"
     ]
    }
   ],
   "source": [
    "# corss_val R2 score for set 3\n",
    "\n",
    "r2_cv3 = round(np.mean(cross_val_score(rf,train_data_3,y_set_3,cv=4, scoring='r2')),3)\n",
    "adjusted_r2_cv3 =  round(1 - (((1 - r2_cv)*(len(y_set_3)-1))/(len(y_set_3) - train_data_3.shape[1] -1)),3)\n",
    "\n",
    "print('R-squared cross validation  for data set 3: ', r2_cv3)\n",
    "print('Adjusted R-squared cross validation  for data set 3: ', adjusted_r2_cv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.) Feature Set 4: Remove highly correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1) Get correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1) Get correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X10</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>...</th>\n",
       "      <th>X372</th>\n",
       "      <th>X373</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033092</td>\n",
       "      <td>-0.028813</td>\n",
       "      <td>-0.100507</td>\n",
       "      <td>-0.002532</td>\n",
       "      <td>-0.005946</td>\n",
       "      <td>-0.010166</td>\n",
       "      <td>-0.038569</td>\n",
       "      <td>-0.047406</td>\n",
       "      <td>-0.005946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002532</td>\n",
       "      <td>-0.016270</td>\n",
       "      <td>0.165268</td>\n",
       "      <td>-0.028625</td>\n",
       "      <td>-0.074267</td>\n",
       "      <td>-0.016874</td>\n",
       "      <td>-0.011377</td>\n",
       "      <td>-0.010482</td>\n",
       "      <td>-0.010166</td>\n",
       "      <td>-0.004741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X12</th>\n",
       "      <td>-0.033092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214812</td>\n",
       "      <td>-0.246596</td>\n",
       "      <td>-0.006214</td>\n",
       "      <td>-0.014588</td>\n",
       "      <td>-0.024943</td>\n",
       "      <td>-0.094629</td>\n",
       "      <td>-0.116311</td>\n",
       "      <td>-0.014588</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006214</td>\n",
       "      <td>0.176652</td>\n",
       "      <td>-0.107917</td>\n",
       "      <td>-0.070232</td>\n",
       "      <td>0.030090</td>\n",
       "      <td>-0.016053</td>\n",
       "      <td>-0.027914</td>\n",
       "      <td>-0.005572</td>\n",
       "      <td>-0.024943</td>\n",
       "      <td>-0.011631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X13</th>\n",
       "      <td>-0.028813</td>\n",
       "      <td>0.214812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083200</td>\n",
       "      <td>-0.005410</td>\n",
       "      <td>-0.012701</td>\n",
       "      <td>-0.021718</td>\n",
       "      <td>-0.082394</td>\n",
       "      <td>-0.043152</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005410</td>\n",
       "      <td>-0.034758</td>\n",
       "      <td>-0.169772</td>\n",
       "      <td>-0.061151</td>\n",
       "      <td>0.357211</td>\n",
       "      <td>-0.036048</td>\n",
       "      <td>-0.024305</td>\n",
       "      <td>0.023040</td>\n",
       "      <td>-0.021718</td>\n",
       "      <td>-0.010127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X14</th>\n",
       "      <td>-0.100507</td>\n",
       "      <td>-0.246596</td>\n",
       "      <td>-0.083200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018872</td>\n",
       "      <td>-0.044305</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>-0.287408</td>\n",
       "      <td>-0.353259</td>\n",
       "      <td>-0.044305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018872</td>\n",
       "      <td>-0.054831</td>\n",
       "      <td>0.118827</td>\n",
       "      <td>0.026448</td>\n",
       "      <td>-0.097617</td>\n",
       "      <td>-0.037991</td>\n",
       "      <td>0.103299</td>\n",
       "      <td>0.007726</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.023598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X15</th>\n",
       "      <td>-0.002532</td>\n",
       "      <td>-0.006214</td>\n",
       "      <td>-0.005410</td>\n",
       "      <td>-0.018872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001116</td>\n",
       "      <td>-0.001909</td>\n",
       "      <td>-0.007242</td>\n",
       "      <td>-0.008901</td>\n",
       "      <td>-0.001116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>-0.003055</td>\n",
       "      <td>-0.014922</td>\n",
       "      <td>-0.005375</td>\n",
       "      <td>0.032166</td>\n",
       "      <td>-0.003168</td>\n",
       "      <td>-0.002136</td>\n",
       "      <td>-0.001968</td>\n",
       "      <td>-0.001909</td>\n",
       "      <td>-0.000890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X10       X12       X13       X14       X15       X16       X17  \\\n",
       "X10  1.000000 -0.033092 -0.028813 -0.100507 -0.002532 -0.005946 -0.010166   \n",
       "X12 -0.033092  1.000000  0.214812 -0.246596 -0.006214 -0.014588 -0.024943   \n",
       "X13 -0.028813  0.214812  1.000000 -0.083200 -0.005410 -0.012701 -0.021718   \n",
       "X14 -0.100507 -0.246596 -0.083200  1.000000 -0.018872 -0.044305  0.012696   \n",
       "X15 -0.002532 -0.006214 -0.005410 -0.018872  1.000000 -0.001116 -0.001909   \n",
       "\n",
       "          X19       X20       X21    ...         X372      X373      X375  \\\n",
       "X10 -0.038569 -0.047406 -0.005946    ...    -0.002532 -0.016270  0.165268   \n",
       "X12 -0.094629 -0.116311 -0.014588    ...    -0.006214  0.176652 -0.107917   \n",
       "X13 -0.082394 -0.043152  0.007212    ...    -0.005410 -0.034758 -0.169772   \n",
       "X14 -0.287408 -0.353259 -0.044305    ...    -0.018872 -0.054831  0.118827   \n",
       "X15 -0.007242 -0.008901 -0.001116    ...    -0.000476 -0.003055 -0.014922   \n",
       "\n",
       "         X376      X377      X378      X379      X380      X382      X383  \n",
       "X10 -0.028625 -0.074267 -0.016874 -0.011377 -0.010482 -0.010166 -0.004741  \n",
       "X12 -0.070232  0.030090 -0.016053 -0.027914 -0.005572 -0.024943 -0.011631  \n",
       "X13 -0.061151  0.357211 -0.036048 -0.024305  0.023040 -0.021718 -0.010127  \n",
       "X14  0.026448 -0.097617 -0.037991  0.103299  0.007726  0.012696  0.023598  \n",
       "X15 -0.005375  0.032166 -0.003168 -0.002136 -0.001968 -0.001909 -0.000890  \n",
       "\n",
       "[5 rows x 268 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation matrix using corr()\n",
    "corr_matrix = train_binary_features_set_3.corr()\n",
    "corr_matrix.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2) Remove highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the Set 4 train data:  (4208, 406)\n"
     ]
    }
   ],
   "source": [
    "# Filter out features with correlation higher than 0.95\n",
    "\n",
    "corr_fea = []\n",
    "for row_number in range (corr_matrix.shape[0]):\n",
    "    for column_number in range (row_number):\n",
    "        if corr_matrix.iloc[row_number,column_number]>0.95:   # this correlation threshold has been chosen intuitively\n",
    "            corr_fea.append(corr_matrix.index[row_number])\n",
    "corr_fea = set(corr_fea)\n",
    "train_binary_features_set_4 = train_binary_features_set_3.drop(corr_fea,axis=1)\n",
    "\n",
    "# Concatanate the ID, Categorical, Binary features\n",
    "train_data_4 = np.hstack((ID_set_3,train_categorical_ohe_set_3,train_binary_features_set_4))\n",
    "print('shape of the Set 4 train data: ',train_data_4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2) RF Regression Using Set 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 6.2.1) Build the RF Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=3, n_estimators=20, random_state=3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a RF Regressor on Set 4\n",
    "rf = RandomForestRegressor(n_estimators=20, max_depth=3, random_state=3)\n",
    "rf.fit(train_data_4,y_set_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.2) Get R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for training data set 4:  0.597\n",
      "Adjusted R-squared for training data set 4:  0.563\n"
     ]
    }
   ],
   "source": [
    "# Get the R2 Score for Feature Set 4\n",
    "\n",
    "r2_training4 =  round(r2_score(y_set_3,rf.predict(train_data_4)),3)\n",
    "adjusted_r2_training4 = round(1 - (((1 - r2_training)*(len(y_set_3))-1)/(len(y_set_3) - train_data_4.shape[1] -1)),3)\n",
    "\n",
    "print('R-squared for training data set 4: ', r2_training4)\n",
    "print('Adjusted R-squared for training data set 4: ', adjusted_r2_training4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.2) Get cross_val R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared cross validation for set 4:  0.505\n",
      "Adjusted R-squared cross validation  for set 4:  0.483\n"
     ]
    }
   ],
   "source": [
    "# Get the cross-val R2 Score for Feature Set 4\n",
    "\n",
    "r2_cv4 = round(np.mean(cross_val_score(rf,train_data_4,y_set_3,cv=4, scoring='r2')),3)\n",
    "adjusted_r2_cv4 =  round(1 - (((1 - r2_cv)*(len(y_set_3)-1))/(len(y_set_3) - train_data_4.shape[1] -1)),3)\n",
    "\n",
    "print('R-squared cross validation for set 4: ', r2_cv4)\n",
    "print('Adjusted R-squared cross validation  for set 4: ',adjusted_r2_cv4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.) Feature Set 5 - Create Interaction Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1) Get Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [10:22<00:00,  2.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get two way and three way interactions for binary features\n",
    "# Get point biserial correlation scores for all interactions\n",
    "\n",
    "R2_int_fea = {}\n",
    "for i in tqdm(range(train_binary_features_set_4.shape[1])):\n",
    "    for j in range(i+1, train_binary_features_set_4.shape[1]):\n",
    "        int_fea = train_binary_features_set_4[train_binary_features_set_4.columns[i]]+train_binary_features_set_4[train_binary_features_set_4.columns[j]]\n",
    "        pbc = pointbiserialr(int_fea,y_set_3)\n",
    "        R2_int_fea[train_binary_features_set_4.columns[i]+'+'+train_binary_features_set_4.columns[j]] = pbc[0]\n",
    "        for k in range(j+1, train_binary_features_set_4.shape[1]):\n",
    "            int_fea = train_binary_features_set_4[train_binary_features_set_4.columns[i]]+\\\n",
    "                      train_binary_features_set_4[train_binary_features_set_4.columns[j]]+\\\n",
    "                      train_binary_features_set_4[train_binary_features_set_4.columns[k]]\n",
    "            pbc = pointbiserialr(int_fea,y_set_3)\n",
    "            R2_int_fea[train_binary_features_set_4.columns[i]+'+'+train_binary_features_set_4.columns[j]+\\\n",
    "                     '+'+train_binary_features_set_4.columns[k]] = pbc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2) Seperate Best interaction features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.1) Sort the interaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction features that have highest point biserial scores:  ['X127+X166+X276', 'X127+X166+X272', 'X136+X261+X315']\n"
     ]
    }
   ],
   "source": [
    "# Point biserial ranges from -1 to +1, 0 means no correlation.\n",
    "Int_fea_best = []\n",
    "for i in (sorted(R2_int_fea.items(), key = lambda item:item[1])):\n",
    "  if abs(i[1]) > 0.70:  # this threshold value was chosen intuitively with trial and eror\n",
    "        Int_fea_best.append(i[0])\n",
    "print(\"Interaction features that have highest point biserial scores: \", Int_fea_best[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.2) Concatanate the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the Set 5 train data:  (4208, 409)\n"
     ]
    }
   ],
   "source": [
    "# Include the interaction featueres in the data set\n",
    "train_binary_features_set_5 = train_binary_features_set_4\n",
    "train_binary_features_set_5['X130+X261+X315'] = train_binary_features_set_4['X130'] + train_binary_features_set_4['X261']+train_binary_features_set_4['X315']\n",
    "train_binary_features_set_5['X136+X179+X261'] = train_binary_features_set_4['X136'] + train_binary_features_set_4['X179']+train_binary_features_set_4['X261']\n",
    "train_binary_features_set_5['X136+X261+X315'] = train_binary_features_set_4['X136'] + train_binary_features_set_4['X261']+train_binary_features_set_4['X315']\n",
    "\n",
    "train_data_5 = np.hstack((ID_set_3,train_categorical_ohe_set_3,train_binary_features_set_5))\n",
    "print('shape of the Set 5 train data: ',train_data_5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3) RF Using Set 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 7.3.1) Build the RF Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=3, n_estimators=20, random_state=3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a RF Regressor on Set 5\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=20, max_depth=3, random_state=3)\n",
    "rf.fit(train_data_5,y_set_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2) Get R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for training data set 5:  0.605\n",
      "Adjusted R-squared for training data set 5:  0.563\n"
     ]
    }
   ],
   "source": [
    "# Get the R2 Score for Feature Set 5\n",
    "\n",
    "r2_training5 =  round(r2_score(y_set_3,rf.predict(train_data_5)),3)\n",
    "adjusted_r2_training5 = round(1 - (((1 - r2_training)*(len(y_set_3)-1))/(len(y_set_3) - train_data_5.shape[1] -1)),3)\n",
    "\n",
    "print('R-squared for training data set 5: ', r2_training5)\n",
    "print('Adjusted R-squared for training data set 5: ', adjusted_r2_training5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2) Get cross_val R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared cross validation  for set 5:  0.531\n",
      "Adjusted R-squared cross validation for set 5:  0.482\n"
     ]
    }
   ],
   "source": [
    "# Get the cross_val R2 Score for Feature Set 5\n",
    "\n",
    "r2_cv5 = round(np.mean(cross_val_score(rf,train_data_5,y_set_3,cv=4, scoring='r2')),3)\n",
    "adjusted_r2_cv5 =  round(1 - (((1 - r2_cv)*(len(y_set_3)-1))/(len(y_set_3) - train_data_5.shape[1] -1)),3)\n",
    "\n",
    "print('R-squared cross validation  for set 5: ', r2_cv5)\n",
    "print('Adjusted R-squared cross validation for set 5: ', adjusted_r2_cv5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.) Feature Set 6 - Create PCA Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1) Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the pca features array:  (4208, 5)\n"
     ]
    }
   ],
   "source": [
    "# Create a new PCA features: PCA Features. \n",
    "\n",
    "pca = PCA(n_components=5, random_state=3)\n",
    "pca_fea = pca.fit_transform(train_binary_features.drop(labels=883,axis=0))\n",
    "print('shape of the pca features array: ', pca_fea.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2) Prepare the train data set 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the train data set 6:  (4208, 414)\n"
     ]
    }
   ],
   "source": [
    "# Concatanate the features\n",
    "train_data_6 = np.hstack((ID_set_3,train_categorical_ohe_set_3,train_binary_features_set_5,pca_fea))\n",
    "print(\"shape of the train data set 6: \", train_data_6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3) RandomForest On Set 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 8.3.1) Build the RF Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=3, n_estimators=20, random_state=3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a RF Regressor on Set 6\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=20, max_depth=3, random_state=3)\n",
    "rf.fit(train_data_6,y_set_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.2) Get R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for training data for set 6:  0.605\n",
      "Adjusted R-squared for training data set 6:  0.562\n"
     ]
    }
   ],
   "source": [
    "# Get the R2 Score for Feature Set 6\n",
    "\n",
    "r2_training6 =  round(r2_score(y_set_3,rf.predict(train_data_6)),3)\n",
    "adjusted_r2_training6 = round(1 - (((1 - r2_training)*(len(y_set_3)-1))/(len(y_set_3) - train_data_6.shape[1] -1)),3)\n",
    "\n",
    "print('R-squared for training data for set 6: ',r2_training6)\n",
    "print('Adjusted R-squared for training data set 6: ', adjusted_r2_training6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.2) Get cross_val R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared cross validation  for set 6:  0.533\n",
      "Adjusted R-squared cross validation  for set 6:  0.482\n"
     ]
    }
   ],
   "source": [
    "# Get the cross_val R2 Score for Feature Set 6\n",
    "\n",
    "r2_cv6 = round(np.mean(cross_val_score(rf,train_data_6,y_set_3,cv=4, scoring='r2')),3)\n",
    "adjusted_r2_cv6 =  round(1 - (((1 - r2_cv)*(len(y_set_3)-1))/(len(y_set_3) - train_data_6.shape[1] -1)),3)\n",
    "\n",
    "print('R-squared cross validation  for set 6: ', r2_cv6)\n",
    "print('Adjusted R-squared cross validation  for set 6: ', adjusted_r2_cv6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.) Results of Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colate the R-squared scores for all feature-sets in table\n",
    "\n",
    "Fe_Results = PrettyTable([\"S.No.\", \"Feature Set\", \"R2\", \"Cross_val R2\", \"Adjusted R2\", \"Cross_val Adjusted R2\"])\n",
    "Fe_Results.add_row([\"1\", \"With Original Features\", r2_training1, adjusted_r2_training1, r2_cv1, adjusted_r2_cv1])\n",
    "Fe_Results.add_row([\"2\", \"Remove Small R2 Features\",  r2_training2, adjusted_r2_training2, r2_cv2, adjusted_r2_cv2])\n",
    "Fe_Results.add_row([\"3\", \"Remove Outliers\",  r2_training3, adjusted_r2_training3, r2_cv3, adjusted_r2_cv3])\n",
    "Fe_Results.add_row([\"4\", \"Remove Correlated Features\",  r2_training4, adjusted_r2_training4, r2_cv4, adjusted_r2_cv4])\n",
    "Fe_Results.add_row([\"5\", \"Add Interaction Features\",  r2_training5, adjusted_r2_training5, r2_cv5, adjusted_r2_cv5])\n",
    "Fe_Results.add_row([\"6\", \"Add PCA Features\", r2_training6, adjusted_r2_training6, r2_cv6, adjusted_r2_cv6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------+-------+--------------+-------------+-----------------------+\n",
      "| S.No. |        Feature Set         |   R2  | Cross_val R2 | Adjusted R2 | Cross_val Adjusted R2 |\n",
      "+-------+----------------------------+-------+--------------+-------------+-----------------------+\n",
      "|   1   |   With Original Features   | 0.576 |    0.544     |    0.512    |          0.46         |\n",
      "|   2   |  Remove Small R2 Features  | 0.576 |    0.557     |    0.511    |         0.475         |\n",
      "|   3   |      Remove Outliers       | 0.603 |    0.557     |    0.523    |         0.475         |\n",
      "|   4   | Remove Correlated Featyres | 0.597 |    0.563     |    0.505    |         0.483         |\n",
      "|   5   |  Add Interaction Features  | 0.605 |    0.563     |    0.531    |         0.482         |\n",
      "|   6   |      Add PCA Features      | 0.605 |    0.562     |    0.533    |         0.482         |\n",
      "+-------+----------------------------+-------+--------------+-------------+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "# Show the result table\n",
    "print(Fe_Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
